#!/usr/bin/env python3
"""
Script Ä‘á»ƒ chuyá»ƒn Ä‘á»•i HuggingFace dataset sang Ä‘á»‹nh dáº¡ng TSV cho ZipVoice fine-tuning.

Dataset structure expected:
DatasetDict({
    train: Dataset({
        features: ['channel', 'text', 'audio'],
        num_rows: 2508
    })
})

Usage:
python convert_hf_to_tsv.py --dataset-name your_hf_dataset --output-dir data/raw
"""

import argparse
import os
import random
from pathlib import Path
import numpy as np
import soundfile as sf
from datasets import load_dataset
import hashlib


def create_unique_id(text: str, index: int) -> str:
    """Táº¡o unique ID tá»« text vÃ  index."""
    # Táº¡o hash tá»« text Ä‘á»ƒ Ä‘áº£m báº£o unique
    text_hash = hashlib.md5(text.encode('utf-8')).hexdigest()[:8]
    return f"hf_{index"06d"}_{text_hash}"


def save_audio_to_wav(audio_array: np.ndarray, sampling_rate: int, output_path: str) -> str:
    """LÆ°u audio array thÃ nh file WAV vÃ  tráº£ vá» Ä‘Æ°á»ng dáº«n Ä‘áº§y Ä‘á»§."""
    # Äáº£m báº£o thÆ° má»¥c tá»“n táº¡i
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    # Normalize audio array náº¿u cáº§n
    if audio_array.dtype != np.float32:
        audio_array = audio_array.astype(np.float32)

    # LÆ°u file WAV
    sf.write(output_path, audio_array, sampling_rate)
    return output_path


def convert_hf_to_tsv(dataset_name: str, output_dir: str = "data/raw", split_ratio: float = 0.9):
    """
    Chuyá»ƒn Ä‘á»•i HF dataset sang Ä‘á»‹nh dáº¡ng TSV cho ZipVoice.

    Args:
        dataset_name: TÃªn hoáº·c path cá»§a HF dataset
        output_dir: ThÆ° má»¥c Ä‘áº§u ra cho TSV vÃ  audio files
        split_ratio: Tá»· lá»‡ chia train/dev (default 0.9 = 90% train, 10% dev)
    """
    print(f"Loading dataset: {dataset_name}")
    try:
        # Load dataset tá»« HF Hub hoáº·c local path
        if os.path.exists(dataset_name):
            dataset = load_dataset('json', data_files=dataset_name)
        else:
            dataset = load_dataset(dataset_name)
    except Exception as e:
        print(f"Error loading dataset: {e}")
        return

    print(f"Dataset loaded with splits: {list(dataset.keys())}")

    # Táº¡o output directories
    raw_dir = Path(output_dir)
    audio_dir = raw_dir / "audio"
    audio_dir.mkdir(parents=True, exist_ok=True)

    # Xá»­ lÃ½ tá»«ng split (thÆ°á»ng chá»‰ cÃ³ 'train')
    for split_name, split_data in dataset.items():
        print(f"Processing split: {split_name} ({len(split_data)} samples)")

        # Trá»™n dá»¯ liá»‡u Ä‘á»ƒ chia train/dev ngáº«u nhiÃªn
        indices = list(range(len(split_data)))
        random.shuffle(indices)

        train_size = int(len(indices) * split_ratio)
        train_indices = indices[:train_size]
        dev_indices = indices[train_size:]

        print(f"Split: {len(train_indices)} train, {len(dev_indices)} dev samples")

        # Táº¡o TSV files cho train vÃ  dev
        for subset_name, subset_indices in [("train", train_indices), ("dev", dev_indices)]:
            tsv_path = raw_dir / f"custom_{subset_name}.tsv"
            print(f"Creating {tsv_path}...")

            with open(tsv_path, 'w', encoding='utf-8') as tsv_file:
                for idx in subset_indices:
                    sample = split_data[idx]

                    # Láº¥y thÃ´ng tin tá»« sample
                    text = sample['text'].strip()
                    speaker_id = sample.get('channel', 'unknown')
                    audio_info = sample['audio']

                    # Táº¡o unique ID
                    uniq_id = create_unique_id(text, idx)

                    # Xá»­ lÃ½ audio
                    audio_array = audio_info['array']
                    sampling_rate = audio_info['sampling_rate']
                    original_path = audio_info.get('path', f'unknown_{idx}.wav')

                    # Táº¡o tÃªn file WAV má»›i
                    wav_filename = f"{uniq_id}_{speaker_id}.wav"
                    wav_path = audio_dir / wav_filename

                    # LÆ°u audio thÃ nh file WAV
                    full_wav_path = save_audio_to_wav(audio_array, sampling_rate, str(wav_path))

                    # Ghi vÃ o TSV file
                    # Format: {uniq_id}\t{text}\t{wav_path}
                    tsv_line = f"{uniq_id}\t{text}\t{full_wav_path}\n"
                    tsv_file.write(tsv_line)

            print(f"Created {tsv_path} with {len(subset_indices)} entries")

    print("
âœ… Conversion completed!"    print(f"ğŸ“ TSV files created in: {raw_dir}")
    print(f"ğŸµ Audio files saved in: {audio_dir}")
    print("
ğŸ“‹ Next steps:"    print("1. Run: bash run_finetune.sh")
    print("2. Or manually run the stages in run_finetune.sh")


def main():
    parser = argparse.ArgumentParser(description="Convert HF dataset to TSV format for ZipVoice fine-tuning")
    parser.add_argument("--dataset-name", required=True,
                        help="HF dataset name or local path")
    parser.add_argument("--output-dir", default="data/raw",
                        help="Output directory for TSV and audio files")
    parser.add_argument("--split-ratio", type=float, default=0.9,
                        help="Train/dev split ratio (default: 0.9)")

    args = parser.parse_args()

    convert_hf_to_tsv(args.dataset_name, args.output_dir, args.split_ratio)


if __name__ == "__main__":
    main()
